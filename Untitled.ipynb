{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb00001-250e-4d5f-adac-279072294aaf",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56317df3-bfee-441d-b5aa-903970a04938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import sys\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcf588d-6889-46f5-bca4-19576cfe4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_data(txt_path: str):\n",
    "    assert txt_path.endswith(\".txt\")\n",
    "    with open(txt_path, \"r\",encoding='UTF8') as file:\n",
    "        return [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f96d99-24a2-4071-a21c-7465851e6913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = \"./data/train_data.txt\" \n",
    "train_data = get_txt_data(train_data_path)\n",
    "test_data_path = \"./data/test_data_solution.txt\" \n",
    "test_data = get_txt_data(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355d89fc-4da9-424e-a539-a2e03a601c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(title):\n",
    "    title = re.sub(r'[\\(\\d\\)]{6}','',title)\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74887183-a88f-4b9d-b0d3-1319cbb9fbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', \"Edgar's Lunch (1998)\", 'thriller', \"L.R. Brane loves his life - his car, his apartment, his job, but especially his girlfriend, Vespa. One day while showering, Vespa runs out of shampoo. L.R. runs across the street to a convenience store to buy some more, a quick trip of no more than a few minutes. When he returns, Vespa is gone and every trace of her existence has been wiped out. L.R.'s life becomes a tortured existence as one strange event after another occurs to confirm in his mind that a conspiracy is working against his finding Vespa.\"]\n",
      "4\n",
      "Edgar's Lunch thriller\n"
     ]
    }
   ],
   "source": [
    "#for sentence in train_data:\n",
    "for sentence in test_data:\n",
    "    sentence = sentence.split(' ::: ')\n",
    "    title  = clean_date(sentence[1])\n",
    "    #label = sentence[2]\n",
    "    description = sentence[2]\n",
    "    whole = title + description\n",
    "    print(sentence)\n",
    "    print(len(sentence))\n",
    "    print(whole)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ce91a79-a7e1-4050-ae2e-6ebe6ad36dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'drama', 'sentence': 'Oscar et la dame rose Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'}\n"
     ]
    }
   ],
   "source": [
    "big_list = []\n",
    "for sentence in train_data:\n",
    "    dictionary = {}\n",
    "    sentence = sentence.split(' ::: ')\n",
    "    title  = clean_date(sentence[1])\n",
    "    label = sentence[2]\n",
    "    description = sentence[3]\n",
    "    whole = title+description\n",
    "    dictionary['label']=label\n",
    "    dictionary['sentence']=whole\n",
    "    big_list.append(dictionary)\n",
    "print(len(big_list))\n",
    "with open(\"make_jsonl.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: for i in row_data: file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17215bc1-331d-4dfd-a1fe-04838d520641",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = './data/train.jsonl'\n",
    "#json_file = './data/test_solution.json'\n",
    "\n",
    "labels_dict = collections.defaultdict(list)\n",
    "for sentence in train_data:\n",
    "    sentence = sentence.split(' ::: ')\n",
    "    title  = clean_date(sentence[1])\n",
    "    label = sentence[2]\n",
    "    description = sentence[3]\n",
    "    whole = title+description\n",
    "    labels_dict['label'].append(label)\n",
    "    labels_dict['sentence'].append(whole)\n",
    "out_file = open(json_file, encoding 'w')    \n",
    "json.dump(labels_dict,out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9539859b-754d-4408-a7cc-cd8d4889c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54214\n"
     ]
    }
   ],
   "source": [
    "#jsonl_file = './data/train.jsonl'\n",
    "jsonl_file = './data/test_solution.jsonl'\n",
    "big_list = []\n",
    "for sentence in train_data:\n",
    "    dictionary = {}\n",
    "    sentence = sentence.split(' ::: ')\n",
    "    title  = clean_date(sentence[1])\n",
    "    label = sentence[2]\n",
    "    description = sentence[3]\n",
    "    whole = title+description\n",
    "    dictionary['label']=label\n",
    "    dictionary['sentence']=whole\n",
    "    big_list.append(dictionary)\n",
    "print(len(big_list))\n",
    "with open(jsonl_file , encoding= \"utf-8\",mode=\"w\") as file:\n",
    "    for i in big_list: file.write(json.dumps(i) + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37f68cdb-f0eb-4e95-905e-694b616a84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_file = './data/train.txt'\n",
    "txt_file = './data/test_solution.txt'\n",
    "with open(txt_file, encoding='utf-8',mode='w') as file:\n",
    "    for sentence in test_data:\n",
    "        sentence = sentence.split(' ::: ')\n",
    "#        title  = clean_date(sentence[1])\n",
    " #       label = sentence[2]\n",
    "        description = sentence[3]\n",
    "#        whole = title+description\n",
    " #       dictionary['label']=label\n",
    "  #      dictionary['sentence']=whole\n",
    "        file.write(description+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844deca-eeae-4a39-87c3-ac96a1858188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fashion-How",
   "language": "python",
   "name": "fashion-how"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
